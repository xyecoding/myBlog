---
title: Personal Thought
top: false
cover: false
toc: true
mathjax: true
date: 2021-12-15 16:01:28
password:
summary:
description: 记录自己在学术方面的一些想法。
categories:
- About Papers
tags:
- Personal Thought
- Papers
- private
---



# Deep Learning

## 什么样的拟合曲面是好的，是深度学习最本质的问题

深度学习的本质就是函数的拟合。泛化性能是衡量深度学习模型性能的指标。

在两个模型都完全拟合训练集的情况下，i.e.，两个模型所表示的函数在训练点处的函数值都是完全正确的。泛化能力要求两函数在测试点处也具有正确的函数值。

这个问题其实只能依赖先验。对于拟合曲面的先验，也就是说，什么样的拟合曲面是好的。

比如，如果点A处函数值为1，那么把A翻转，函数值也为1。这是源于目标识别常识的先验。

数据增广方法mixup，发现不同图片之间函数值线性变换是好的。这是对函数曲面的另一个先验。在样本之间，函数线性变换好。

所以，深度学习的本质问题是什么样的面是好的，如果我们知道什么样的面是好的。知道我们需要拟合的曲面的一些特点，那么就可以利用这些先验来进行数据增广，甚至进行模型的设计。

比如，要拟合的曲面是几次的。是否需要高次非线性。如果需要我们就要引入特张图之间的乘法。强化学习的特征选择给模型带来另一种非线性。哪种非线性是好的？要回答这个问题，就要知道我们需要拟合的那个函数是几次的，是哪种非线性。

**设想如果，有一种可视化方法，直接可视化高维数据。我们用它来可视化在MNIST, CIFAR-10等数据集上都达到100%准确率的函数。我们总结这些函数曲面有什么特点，光不光滑？是几次的？有哪些对称性？。总结出适用于所有数据集的共性的曲面特点。那么我们就能根据这些特点，这些先验，设计出好的算法，提高模型的泛化性能。卷积神经网络之所以在图像上那么成功，也是源于，它拟合的函数一定具有某种对称性（因为对图像平移不变），而这种对称性，就是真实图像对应的理想函数所具有的。**

洞察真实数据是什么样的，是提高模型泛化能力的最终途径。



## 关于特征图乘法的实验

特征图乘法会带来高次非线性。如果把ResNet里面的加法改成加法。。

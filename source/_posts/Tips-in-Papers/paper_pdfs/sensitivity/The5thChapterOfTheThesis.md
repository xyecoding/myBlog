鲁棒性定义-鲁棒性度量（光滑）-正则项， 正则项和鲁棒性的关系。

1. The esoteric nature of dropout has inspired a large body of work studying its
   Regularization effect.
2. Our derivations show that dropout regularizes the stability of the model and
   loss around the training data.
3. Theoretical support for stability-based Regularization.
4. Our results provide insight into how to improve the Regularization of CNNs.
5. This can achieved either through data augmentation that changes the
   underlying statistics of the training sets or through inductive architectural
   biases, such as translation invariance that is inherent in convolutional
   neural networks.
